{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1560c963",
   "metadata": {},
   "source": [
    "<h1><center>Natural Language Processing</center></h1>\n",
    "\n",
    "<h3><center>NLP 08</center></h3>\n",
    "\n",
    "![hM0xGrmJw](https://miro.medium.com/max/720/1*PGB0w1JZslqA-hM0xGrmJw.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446794f3",
   "metadata": {},
   "source": [
    "# Topics\n",
    "1.\tIntroduction to Natural Language Processing\n",
    "2.\tWhy learn NLP?\n",
    "3.\tLet's start playing with Python!\n",
    "4.\tText Wrangling and Cleansing\n",
    " - Sentence splitter\n",
    " - Tokenization\n",
    " - Stemming         \n",
    " - Lemmatization    \n",
    " - Stop word removal\n",
    " - Diving into NLTK\n",
    "5.\tVectorizing with Python\n",
    " - Count Vectorizer \n",
    " - TF-IDF Vectorizer\n",
    "6.\tModelling with Python <---------------------------------------------------- **This is where we are**\n",
    " - Classification\n",
    " - Clustering\n",
    " - Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1eb379",
   "metadata": {},
   "source": [
    "# Reading data with pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "61d73e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('SPAM text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9e3f0400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a210a",
   "metadata": {},
   "source": [
    "# Writing a function to clean out stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fd892fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "my_stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "def datacleaning(mystring):\n",
    "    # Step 1 \n",
    "    # Tokenize the string\n",
    "    my_tokenized_string = word_tokenize(mystring)\n",
    "    \n",
    "    # ----------------- End of step 1 ----------------- #\n",
    "    temp = []\n",
    "    for i in my_tokenized_string:\n",
    "        if i in my_stopwords:\n",
    "            pass\n",
    "        else:\n",
    "            temp.append(i)\n",
    "\n",
    "    my_new_string = ' '.join(temp)\n",
    "    return my_new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "86646a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing our function on our column\n",
    "df['Clean_Message'] = df['Message'].apply(datacleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e58f5755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Clean_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go jurong point , crazy .. Available bugis n g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar ... Joking wif u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say early hor ... U c already say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I n't think goes usf , lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       Clean_Message  \n",
       "0  Go jurong point , crazy .. Available bugis n g...  \n",
       "1                    Ok lar ... Joking wif u oni ...  \n",
       "2  Free entry 2 wkly comp win FA Cup final tkts 2...  \n",
       "3        U dun say early hor ... U c already say ...  \n",
       "4     Nah I n't think goes usf , lives around though  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776db39",
   "metadata": {},
   "source": [
    "<h1><center>Remember</center></h1>\n",
    "\n",
    "\n",
    "# Vectorizing string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a3ac1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4f6d5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialise it\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6130ee64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(['Whatever text we want','We give it as list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7063c3e",
   "metadata": {},
   "source": [
    "### Getting all the vocabulary out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "739a6e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['as', 'give', 'it', 'list', 'text', 'want', 'we', 'whatever'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457332c9",
   "metadata": {},
   "source": [
    "### Getting the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a69c3f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vectorizer.transform(['Whatever text we want','We give it as list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a879abb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4b2a6f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e7446343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['football']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ae90f",
   "metadata": {},
   "source": [
    "<h1><center>Doing the same to a DataFrame Column</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4fb7a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialise it\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "970fd3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(df['Clean_Message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d9dcd",
   "metadata": {},
   "source": [
    "### Getting all the vocabulary out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f3fd74d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '000pes', ..., 'èn', 'ú1', '〨ud'], dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a6613a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '000pes', '008704050406', '0089', '0121',\n",
       "       '01223585236', '01223585334', '0125698789', '02', '0207',\n",
       "       '02072069400', '02073162414', '02085076972', '021', '03', '04',\n",
       "       '0430', '05', '050703', '0578', '06', '07', '07008009200',\n",
       "       '07046744435', '07090201529', '07090298926', '07099833605',\n",
       "       '07123456789', '0721072', '07732584351', '07734396839',\n",
       "       '07742676969', '07753741225', '0776xxxxxxx', '07781482378',\n",
       "       '07786200117', '077xxx', '078', '07801543489', '07808',\n",
       "       '07808247860', '07808726822', '07815296484', '07821230901',\n",
       "       '078498', '07880867867', '0789xxxxxxx', '07946746291',\n",
       "       '0796xxxxxx', '07973788240', '07xxxxxxxxx', '08', '0800',\n",
       "       '08000407165', '08000776320', '08000839402', '08000930705',\n",
       "       '08000938767', '08001950382', '08002888812', '08002986030',\n",
       "       '08002986906', '08002988890', '08006344447', '0808', '08081263000',\n",
       "       '08081560665', '0825', '083', '0844', '08448350055', '08448714184',\n",
       "       '0845', '08450542832', '08452810071', '08452810073',\n",
       "       '08452810075over18', '0870', '08700435505150p', '08700469649',\n",
       "       '08700621170150p', '08701213186', '08701237397', '08701417012',\n",
       "       '08701417012150p', '0870141701216', '087016248', '08701752560',\n",
       "       '087018728737', '0870241182716', '08702490080', '08702840625',\n",
       "       '08704050406', '08704439680', '08704439680ts', '08706091795',\n",
       "       '0870737910216yrs', '08707500020', '08707509020'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4eddb",
   "metadata": {},
   "source": [
    "<h2><center>This is trash</center></h2>\n",
    "\n",
    "![](https://media.giphy.com/media/ZNnBcUZinjJoGdZQkL/giphy.gif)\n",
    "\n",
    "---\n",
    "What are these column names, we can't move forward with this. \n",
    "\n",
    "We need to fix this !!\n",
    "\n",
    "![](https://media.tenor.com/2HiYJsN72X8AAAAC/despicable-me-agnes.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a6752",
   "metadata": {},
   "source": [
    "# Look at what will happen, if we don't fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e5d89c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8683"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d31ae90",
   "metadata": {},
   "source": [
    "### Getting the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "80e70f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vectorizer.transform(df['Clean_Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "163032a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8683 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 52566 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "71216921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84602c",
   "metadata": {},
   "source": [
    "<h2><center>Unacceptable</center></h2>\n",
    "\n",
    "![](https://media.giphy.com/media/H1YGzkKcin3uPaUb58/giphy-downsized-large.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c7b67",
   "metadata": {},
   "source": [
    "# Remove the numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c44bfb",
   "metadata": {},
   "source": [
    "### Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2a75522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1dbd58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "15261bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5293491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f1f3fb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.isdigit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae709de",
   "metadata": {},
   "source": [
    "### Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "04ffbbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in numbers:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "77398530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'@' in '0123456789@#$%^&*)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0d1d1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = 'This is a test string'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee585b",
   "metadata": {},
   "source": [
    "## So, let's write a function that removes numbers from our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "66ae3100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(x):\n",
    "    # Step 1 - Tokenize the string\n",
    "    my_tokenized_string = word_tokenize(x)    \n",
    "    # ----------------- End of step 1 ----------------- #\n",
    "    temp = []\n",
    "    # Step 2 - Loop over your tokens\n",
    "    for i in my_tokenized_string:\n",
    "        # Step 3 - Check if your words are numbers or not\n",
    "        if i.isdigit():\n",
    "            pass\n",
    "        else:\n",
    "            # Step 4 - If they are not numbers, save them\n",
    "            temp.append(i)\n",
    "\n",
    "    # Step 5 - Once saved, stitch them back together\n",
    "    my_new_string = ' '.join(temp)\n",
    "    \n",
    "    # Step 6 - Return the stitched sentence back\n",
    "    return my_new_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77b3df",
   "metadata": {},
   "source": [
    "Let's see if our function woked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "40967bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test string and this99 is another num123ber'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_numbers('This is a test string 100 and this99 is another num123ber 1235')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188de2d6",
   "metadata": {},
   "source": [
    "Works like the way we would expect. \n",
    "\n",
    "### Let's clean our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "68b7f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_Clean_Message'] = df['Clean_Message'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e4af8165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Clean_Message</th>\n",
       "      <th>Number_Clean_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go jurong point , crazy .. Available bugis n g...</td>\n",
       "      <td>Go jurong point , crazy .. Available bugis n g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar ... Joking wif u oni ...</td>\n",
       "      <td>Ok lar ... Joking wif u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say early hor ... U c already say ...</td>\n",
       "      <td>U dun say early hor ... U c already say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I n't think goes usf , lives around though</td>\n",
       "      <td>Nah I n't think goes usf , lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>This 2nd time tried 2 contact u. U £750 Pound ...</td>\n",
       "      <td>This 2nd time tried contact u. U £750 Pound pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>Will ü b going esplanade fr home ?</td>\n",
       "      <td>Will ü b going esplanade fr home ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Pity , * mood . So ... suggestions ?</td>\n",
       "      <td>Pity , * mood . So ... suggestions ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>The guy bitching I acted like 'd interested bu...</td>\n",
       "      <td>The guy bitching I acted like 'd interested bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>Rofl . Its true name</td>\n",
       "      <td>Rofl . Its true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  \\\n",
       "0         ham  Go until jurong point, crazy.. Available only ...   \n",
       "1         ham                      Ok lar... Joking wif u oni...   \n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3         ham  U dun say so early hor... U c already then say...   \n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...       ...                                                ...   \n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568      ham               Will ü b going to esplanade fr home?   \n",
       "5569      ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570      ham  The guy did some bitching but I acted like i'd...   \n",
       "5571      ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                          Clean_Message  \\\n",
       "0     Go jurong point , crazy .. Available bugis n g...   \n",
       "1                       Ok lar ... Joking wif u oni ...   \n",
       "2     Free entry 2 wkly comp win FA Cup final tkts 2...   \n",
       "3           U dun say early hor ... U c already say ...   \n",
       "4        Nah I n't think goes usf , lives around though   \n",
       "...                                                 ...   \n",
       "5567  This 2nd time tried 2 contact u. U £750 Pound ...   \n",
       "5568                 Will ü b going esplanade fr home ?   \n",
       "5569               Pity , * mood . So ... suggestions ?   \n",
       "5570  The guy bitching I acted like 'd interested bu...   \n",
       "5571                               Rofl . Its true name   \n",
       "\n",
       "                                   Number_Clean_Message  \n",
       "0     Go jurong point , crazy .. Available bugis n g...  \n",
       "1                       Ok lar ... Joking wif u oni ...  \n",
       "2     Free entry wkly comp win FA Cup final tkts 21s...  \n",
       "3           U dun say early hor ... U c already say ...  \n",
       "4        Nah I n't think goes usf , lives around though  \n",
       "...                                                 ...  \n",
       "5567  This 2nd time tried contact u. U £750 Pound pr...  \n",
       "5568                 Will ü b going esplanade fr home ?  \n",
       "5569               Pity , * mood . So ... suggestions ?  \n",
       "5570  The guy bitching I acted like 'd interested bu...  \n",
       "5571                               Rofl . Its true name  \n",
       "\n",
       "[5572 rows x 4 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb0130",
   "metadata": {},
   "source": [
    "### Let's do the vectorization again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6f142cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialise it\n",
    "vectorizer2 = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4075978d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.fit(df['Number_Clean_Message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1121d",
   "metadata": {},
   "source": [
    "### Getting all the vocabulary out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0777af57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '000pes', ..., 'èn', 'ú1', '〨ud'], dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2d5e63d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '000pes', '02', '0207', '03', '04', '0430', '05',\n",
       "       '06', '07', '0776xxxxxxx', '07781482378', '077xxx', '07880867867',\n",
       "       '0789xxxxxxx', '07946746291', '0796xxxxxx', '07xxxxxxxxx', '08',\n",
       "       '083', '08452810075over18', '08700435505150p', '08700469649',\n",
       "       '08700621170150p', '08701417012150p', '0870141701216',\n",
       "       '08702840625', '08704050406', '08704439680ts', '0870737910216yrs',\n",
       "       '0870753331018', '0871', '087123002209am', '08712400602450p',\n",
       "       '0871277810710p', '0871277810910p', '08714342399',\n",
       "       '087147123779am', '0871750', '08717890890', '08718720201',\n",
       "       '087187262701', '08718727870', '08718727870150ppm', '09',\n",
       "       '09065171142', '09066649731from', '0a', '0quit', '10', '100',\n",
       "       '1000', '1000call', '1000s', '100p', '100percent', '100txt',\n",
       "       '10am', '10k', '10p', '10ppm', '10th', '11', '114', '118p',\n",
       "       '11mths', '11pm', '12', '120p', '125', '1250', '125gift',\n",
       "       '12hours', '12hrs', '12mths', '13', '14', '140ppm', '1450',\n",
       "       '146tf150p', '14tcr', '14thmarch', '15', '150', '1500', '150p',\n",
       "       '150p16', '150pm', '150ppermesssubscription', '150ppm',\n",
       "       '150ppmpobox10183bhamb64xe', '150ppmsg', '150pw', '15pm', '16',\n",
       "       '165', '18', '18p', '18yrs'], dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.get_feature_names_out()[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0ea754e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8234"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer2.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060c723",
   "metadata": {},
   "source": [
    "# So, we went from 8683 columns to 8234\n",
    "\n",
    "![](https://media.giphy.com/media/nbNWgtnMgIYpUSy3e9/giphy.gif)\n",
    "\n",
    "\n",
    "## That was a complete waste of my time. \n",
    "Well well, looks like I will have to follow approach 2 and nuke the whole thing, all the numbers gotta go. \n",
    "\n",
    "\n",
    "<h2><center>But wait</center></h2>\n",
    "\n",
    "Why should i have all the fun\n",
    "- i have you for that. \n",
    "- Don't we all want to have fun !!\n",
    "\n",
    "![](https://media.giphy.com/media/cXblnKXr2BQOaYnTni/giphy.gif)\n",
    "\n",
    "Well, time for you to follow approach 1 of removing numbers, \n",
    "- Write a function\n",
    "- Implement the function on your column\n",
    "- Vectorize your new column\n",
    "- See how many columns you have. \n",
    "\n",
    "![](https://media.tenor.com/tLMOOEUZ6tsAAAAC/good-luck-spongebob.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8335fc5",
   "metadata": {},
   "source": [
    "<h1><center>Basics Terminology of Machine Learning</center></h1>\n",
    "\n",
    "- Train-Test Split\n",
    "- Accuracy\n",
    "- RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd6cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34162f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0347d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
