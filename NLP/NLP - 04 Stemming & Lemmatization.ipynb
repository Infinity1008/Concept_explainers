{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1560c963",
   "metadata": {},
   "source": [
    "<h1><center>Natural Language Processing</center></h1>\n",
    "\n",
    "<h3><center>NLP 03</center></h3>\n",
    "\n",
    "![hM0xGrmJw](https://miro.medium.com/max/720/1*PGB0w1JZslqA-hM0xGrmJw.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446794f3",
   "metadata": {},
   "source": [
    "# Topics\n",
    "1.\tIntroduction to Natural Language Processing\n",
    "2.\tWhy learn NLP?\n",
    "3.\tLet's start playing with Python!\n",
    "4.\tText Wrangling and Cleansing\n",
    " - Sentence splitter\n",
    " - Tokenization\n",
    " - Stemming         <---------------------------------------------------- **This is where we are**\n",
    " - Lemmatization    <---------------------------------------------------- **This is where we are**\n",
    " - Stop word removal\n",
    " - Diving into NLTK\n",
    "5.\tVectorizing with Python\n",
    " - Count Vectorizer\n",
    " - TF-IDF Vectorizer\n",
    "6.\tModelling with Python\n",
    " - Classification\n",
    " - Clustering\n",
    " - Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d1bfd",
   "metadata": {},
   "source": [
    "# Better Stemming\n",
    "You have a couple of options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc6153",
   "metadata": {},
   "source": [
    "### Snowball stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f525b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plurals = ['caresses', 'flies', 'dies', 'mules', 'denied','died', \n",
    "           'agreed', 'owned', 'humbled', 'sized','meeting', 'stating', \n",
    "           'siezing', 'itemization','sensational', 'traditional', \n",
    "           'reference', 'colonizer','plotted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e851e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0927b2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6be4070",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2fba7255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'understand'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_stemmer.stem(\"understanding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a11b114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a 100\n"
     ]
    }
   ],
   "source": [
    "a = 100\n",
    "print('This is a',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e7545e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a string hello'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'hello'\n",
    "f'This is a string {a}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41e24c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caresses >>> caress\n",
      "flies >>> fli\n",
      "dies >>> die\n",
      "mules >>> mule\n",
      "denied >>> deni\n",
      "died >>> die\n",
      "agreed >>> agre\n",
      "owned >>> own\n",
      "humbled >>> humbl\n",
      "sized >>> size\n",
      "meeting >>> meet\n",
      "stating >>> state\n",
      "siezing >>> siez\n",
      "itemization >>> item\n",
      "sensational >>> sensat\n",
      "traditional >>> tradit\n",
      "reference >>> refer\n",
      "colonizer >>> colon\n",
      "plotted >>> plot\n"
     ]
    }
   ],
   "source": [
    "for word in plurals:\n",
    "    print(f\"{word} >>> {sn_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e1609c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plurals = ['caresses', 'flies', 'dies', 'mules', 'denied','died', \n",
    "           'agreed', 'owned', 'humbled', 'sized','meeting', 'stating', \n",
    "           'siezing', 'itemization','sensational', 'traditional', \n",
    "           'reference', 'colonizer','plotted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb8e9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caresses >>> caress\n",
      "flies >>> fli\n",
      "dies >>> die\n",
      "mules >>> mule\n",
      "denied >>> deni\n",
      "died >>> die\n",
      "agreed >>> agre\n",
      "owned >>> own\n",
      "humbled >>> humbl\n",
      "sized >>> size\n",
      "meeting >>> meet\n",
      "stating >>> state\n",
      "siezing >>> siez\n",
      "itemization >>> item\n",
      "sensational >>> sensat\n",
      "traditional >>> tradit\n",
      "reference >>> refer\n",
      "colonizer >>> colon\n",
      "plotted >>> plot\n"
     ]
    }
   ],
   "source": [
    "for word in plurals:\n",
    "    print(word + ' >>> ' +  sn_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "20189573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 hello'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(10) + ' ' + 'hello'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b86f6c",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "Retrieving the source of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "465faf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Something'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize('Something')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ddedb0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "sn_stemmer = SnowballStemmer(\"english\")\n",
    "sn_stemmer.stem('Running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ff94755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caresses >>> caress\n",
      "flies >>> fly\n",
      "dies >>> dy\n",
      "mules >>> mule\n",
      "denied >>> denied\n",
      "died >>> died\n",
      "agreed >>> agreed\n",
      "owned >>> owned\n",
      "humbled >>> humbled\n",
      "sized >>> sized\n",
      "meeting >>> meeting\n",
      "stating >>> stating\n",
      "siezing >>> siezing\n",
      "itemization >>> itemization\n",
      "sensational >>> sensational\n",
      "traditional >>> traditional\n",
      "reference >>> reference\n",
      "colonizer >>> colonizer\n",
      "plotted >>> plotted\n"
     ]
    }
   ],
   "source": [
    "for word in plurals:\n",
    "    print(f\"{word} >>> {lemmatizer.lemmatize(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e568937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caresses >>> caress\n",
      "flies >>> fli\n",
      "dies >>> die\n",
      "mules >>> mule\n",
      "denied >>> deni\n",
      "died >>> die\n",
      "agreed >>> agre\n",
      "owned >>> own\n",
      "humbled >>> humbl\n",
      "sized >>> size\n",
      "meeting >>> meet\n",
      "stating >>> state\n",
      "siezing >>> siez\n",
      "itemization >>> item\n",
      "sensational >>> sensat\n",
      "traditional >>> tradit\n",
      "reference >>> refer\n",
      "colonizer >>> colon\n",
      "plotted >>> plot\n"
     ]
    }
   ],
   "source": [
    "for word in plurals:\n",
    "    print(word + ' >>> ' +  sn_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a6a62",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- How to install NLTK and it's data\n",
    "- How to use nltk tokenizers\n",
    "- NLTK Stemmers\n",
    "- NLTK Lemmatizers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
