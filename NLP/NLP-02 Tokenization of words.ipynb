{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1560c963",
   "metadata": {},
   "source": [
    "<h1><center>Natural Language Processing</center></h1>\n",
    "\n",
    "![hM0xGrmJw](https://miro.medium.com/max/720/1*PGB0w1JZslqA-hM0xGrmJw.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446794f3",
   "metadata": {},
   "source": [
    "# Topics\n",
    "1.\tIntroduction to Natural Language Processing\n",
    "2.\tWhy learn NLP?\n",
    "3.\tLet's start playing with Python!\n",
    "4.\tText Wrangling and Cleansing\n",
    " - Sentence splitter\n",
    " - Tokenization\n",
    " - Stemming\n",
    " - Lemmatization\n",
    " - Stop word removal\n",
    " - Diving into NLTK\n",
    "5.\tVectorizing with Python\n",
    " - Count Vectorizer\n",
    " - TF-IDF Vectorizer\n",
    "6.\tModelling with Python\n",
    " - Classification\n",
    " - Clustering\n",
    " - Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d7063",
   "metadata": {},
   "source": [
    "# Python strings are collection of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85f0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"My name is Lionel Messi, I am the greatest of all time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a6a956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58121f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be57e6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y na'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632204f2",
   "metadata": {},
   "source": [
    "# String methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d291f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MY NAME IS LIONEL MESSI, I AM THE GREATEST OF ALL TIME'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can do upper \n",
    "a.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d6ef64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is lionel messi, i am the greatest of all time'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can do lower\n",
    "a.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea9698fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Lionel',\n",
       " 'Messi,',\n",
       " 'I',\n",
       " 'am',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'of',\n",
       " 'all',\n",
       " 'time']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can split on space\n",
    "a.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8195db98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My name is Lionel Messi', ' I am the greatest of all time']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can split on commas\n",
    "a.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4749dbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n",
      "y\n",
      " \n",
      "n\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "L\n",
      "i\n",
      "o\n",
      "n\n",
      "e\n",
      "l\n",
      " \n",
      "M\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      ",\n",
      " \n",
      "I\n",
      " \n",
      "a\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "g\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "# You can loop\n",
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac35ca69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_306/2264403170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You can loop and use methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "# You can loop and use methods\n",
    "for i in a:\n",
    "    print(i.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae8834",
   "metadata": {},
   "source": [
    "# Basic flow\n",
    "![](https://devopedia.org/images/article/230/4727.1572189926.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b073b7d0",
   "metadata": {},
   "source": [
    "# Python Libraries for NLP\n",
    "There are many libraries that help up do basic NLP tasks, some of the most popular are\n",
    "# 1. NLTK\n",
    "<img src=\"https://miro.medium.com/max/640/1*YM2HXc7f4v02pZBEO8h-qw.webp\" alt=\"\" width=\"200\" height=\"200\">\n",
    "\n",
    "\n",
    "# 2. Spacy\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/SpaCy_logo.svg/1920px-SpaCy_logo.svg.png\" alt=\"\" width=\"300\" height=\"200\">\n",
    "\n",
    "\n",
    "# 3. Gensim\n",
    "<img src=\"https://repository-images.githubusercontent.com/1349775/202c4680-8f7c-11e9-91c6-745fdcbeffe8\" alt=\"\" width=\"300\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac95cae",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f7285",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/640/1*YM2HXc7f4v02pZBEO8h-qw.webp\" alt=\"\" width=\"200\" height=\"200\">'\n",
    "<h1><center>NLTK</center></h1>\n",
    "NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98952c5c",
   "metadata": {},
   "source": [
    "# Installation\n",
    "```pip install nltk```\n",
    "\n",
    "or \n",
    "\n",
    "```conda install -c anaconda nltk```\n",
    "\n",
    "# Getting data for nltk\n",
    "\n",
    "```import nltk```\n",
    "\n",
    "```nltk.download()```\n",
    "\n",
    "# Let's get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f017562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6da8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"My name is Lionel Messi, I am the greatest of all time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf29c2",
   "metadata": {},
   "source": [
    "# Better words tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6f3c408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Lionel',\n",
       " 'Messi,',\n",
       " 'I',\n",
       " 'am',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'of',\n",
       " 'all',\n",
       " 'time.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f33c65db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Lionel',\n",
       " 'Messi',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'of',\n",
       " 'all',\n",
       " 'time',\n",
       " '.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41344d7",
   "metadata": {},
   "source": [
    "# Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be44ca11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My name is Lionel Messi, I am the greatest of all time.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7270b346",
   "metadata": {},
   "source": [
    "# Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3a4b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82d49e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"My name is Lionel Messi, I am the greatest of all time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f43f8c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['إذ',\n",
       " 'إذا',\n",
       " 'إذما',\n",
       " 'إذن',\n",
       " 'أف',\n",
       " 'أقل',\n",
       " 'أكثر',\n",
       " 'ألا',\n",
       " 'إلا',\n",
       " 'التي',\n",
       " 'الذي',\n",
       " 'الذين',\n",
       " 'اللاتي',\n",
       " 'اللائي',\n",
       " 'اللتان',\n",
       " 'اللتيا',\n",
       " 'اللتين',\n",
       " 'اللذان',\n",
       " 'اللذين',\n",
       " 'اللواتي',\n",
       " 'إلى',\n",
       " 'إليك',\n",
       " 'إليكم',\n",
       " 'إليكما',\n",
       " 'إليكن',\n",
       " 'أم',\n",
       " 'أما',\n",
       " 'أما',\n",
       " 'إما',\n",
       " 'أن',\n",
       " 'إن',\n",
       " 'إنا',\n",
       " 'أنا',\n",
       " 'أنت',\n",
       " 'أنتم',\n",
       " 'أنتما',\n",
       " 'أنتن',\n",
       " 'إنما',\n",
       " 'إنه',\n",
       " 'أنى',\n",
       " 'أنى',\n",
       " 'آه',\n",
       " 'آها',\n",
       " 'أو',\n",
       " 'أولاء',\n",
       " 'أولئك',\n",
       " 'أوه',\n",
       " 'آي',\n",
       " 'أي',\n",
       " 'أيها',\n",
       " 'إي',\n",
       " 'أين',\n",
       " 'أين',\n",
       " 'أينما',\n",
       " 'إيه',\n",
       " 'بخ',\n",
       " 'بس',\n",
       " 'بعد',\n",
       " 'بعض',\n",
       " 'بك',\n",
       " 'بكم',\n",
       " 'بكم',\n",
       " 'بكما',\n",
       " 'بكن',\n",
       " 'بل',\n",
       " 'بلى',\n",
       " 'بما',\n",
       " 'بماذا',\n",
       " 'بمن',\n",
       " 'بنا',\n",
       " 'به',\n",
       " 'بها',\n",
       " 'بهم',\n",
       " 'بهما',\n",
       " 'بهن',\n",
       " 'بي',\n",
       " 'بين',\n",
       " 'بيد',\n",
       " 'تلك',\n",
       " 'تلكم',\n",
       " 'تلكما',\n",
       " 'ته',\n",
       " 'تي',\n",
       " 'تين',\n",
       " 'تينك',\n",
       " 'ثم',\n",
       " 'ثمة',\n",
       " 'حاشا',\n",
       " 'حبذا',\n",
       " 'حتى',\n",
       " 'حيث',\n",
       " 'حيثما',\n",
       " 'حين',\n",
       " 'خلا',\n",
       " 'دون',\n",
       " 'ذا',\n",
       " 'ذات',\n",
       " 'ذاك',\n",
       " 'ذان',\n",
       " 'ذانك',\n",
       " 'ذلك',\n",
       " 'ذلكم',\n",
       " 'ذلكما',\n",
       " 'ذلكن',\n",
       " 'ذه',\n",
       " 'ذو',\n",
       " 'ذوا',\n",
       " 'ذواتا',\n",
       " 'ذواتي',\n",
       " 'ذي',\n",
       " 'ذين',\n",
       " 'ذينك',\n",
       " 'ريث',\n",
       " 'سوف',\n",
       " 'سوى',\n",
       " 'شتان',\n",
       " 'عدا',\n",
       " 'عسى',\n",
       " 'عل',\n",
       " 'على',\n",
       " 'عليك',\n",
       " 'عليه',\n",
       " 'عما',\n",
       " 'عن',\n",
       " 'عند',\n",
       " 'غير',\n",
       " 'فإذا',\n",
       " 'فإن',\n",
       " 'فلا',\n",
       " 'فمن',\n",
       " 'في',\n",
       " 'فيم',\n",
       " 'فيما',\n",
       " 'فيه',\n",
       " 'فيها',\n",
       " 'قد',\n",
       " 'كأن',\n",
       " 'كأنما',\n",
       " 'كأي',\n",
       " 'كأين',\n",
       " 'كذا',\n",
       " 'كذلك',\n",
       " 'كل',\n",
       " 'كلا',\n",
       " 'كلاهما',\n",
       " 'كلتا',\n",
       " 'كلما',\n",
       " 'كليكما',\n",
       " 'كليهما',\n",
       " 'كم',\n",
       " 'كم',\n",
       " 'كما',\n",
       " 'كي',\n",
       " 'كيت',\n",
       " 'كيف',\n",
       " 'كيفما',\n",
       " 'لا',\n",
       " 'لاسيما',\n",
       " 'لدى',\n",
       " 'لست',\n",
       " 'لستم',\n",
       " 'لستما',\n",
       " 'لستن',\n",
       " 'لسن',\n",
       " 'لسنا',\n",
       " 'لعل',\n",
       " 'لك',\n",
       " 'لكم',\n",
       " 'لكما',\n",
       " 'لكن',\n",
       " 'لكنما',\n",
       " 'لكي',\n",
       " 'لكيلا',\n",
       " 'لم',\n",
       " 'لما',\n",
       " 'لن',\n",
       " 'لنا',\n",
       " 'له',\n",
       " 'لها',\n",
       " 'لهم',\n",
       " 'لهما',\n",
       " 'لهن',\n",
       " 'لو',\n",
       " 'لولا',\n",
       " 'لوما',\n",
       " 'لي',\n",
       " 'لئن',\n",
       " 'ليت',\n",
       " 'ليس',\n",
       " 'ليسا',\n",
       " 'ليست',\n",
       " 'ليستا',\n",
       " 'ليسوا',\n",
       " 'ما',\n",
       " 'ماذا',\n",
       " 'متى',\n",
       " 'مذ',\n",
       " 'مع',\n",
       " 'مما',\n",
       " 'ممن',\n",
       " 'من',\n",
       " 'منه',\n",
       " 'منها',\n",
       " 'منذ',\n",
       " 'مه',\n",
       " 'مهما',\n",
       " 'نحن',\n",
       " 'نحو',\n",
       " 'نعم',\n",
       " 'ها',\n",
       " 'هاتان',\n",
       " 'هاته',\n",
       " 'هاتي',\n",
       " 'هاتين',\n",
       " 'هاك',\n",
       " 'هاهنا',\n",
       " 'هذا',\n",
       " 'هذان',\n",
       " 'هذه',\n",
       " 'هذي',\n",
       " 'هذين',\n",
       " 'هكذا',\n",
       " 'هل',\n",
       " 'هلا',\n",
       " 'هم',\n",
       " 'هما',\n",
       " 'هن',\n",
       " 'هنا',\n",
       " 'هناك',\n",
       " 'هنالك',\n",
       " 'هو',\n",
       " 'هؤلاء',\n",
       " 'هي',\n",
       " 'هيا',\n",
       " 'هيت',\n",
       " 'هيهات',\n",
       " 'والذي',\n",
       " 'والذين',\n",
       " 'وإذ',\n",
       " 'وإذا',\n",
       " 'وإن',\n",
       " 'ولا',\n",
       " 'ولكن',\n",
       " 'ولو',\n",
       " 'وما',\n",
       " 'ومن',\n",
       " 'وهو',\n",
       " 'يا',\n",
       " 'أبٌ',\n",
       " 'أخٌ',\n",
       " 'حمٌ',\n",
       " 'فو',\n",
       " 'أنتِ',\n",
       " 'يناير',\n",
       " 'فبراير',\n",
       " 'مارس',\n",
       " 'أبريل',\n",
       " 'مايو',\n",
       " 'يونيو',\n",
       " 'يوليو',\n",
       " 'أغسطس',\n",
       " 'سبتمبر',\n",
       " 'أكتوبر',\n",
       " 'نوفمبر',\n",
       " 'ديسمبر',\n",
       " 'جانفي',\n",
       " 'فيفري',\n",
       " 'مارس',\n",
       " 'أفريل',\n",
       " 'ماي',\n",
       " 'جوان',\n",
       " 'جويلية',\n",
       " 'أوت',\n",
       " 'كانون',\n",
       " 'شباط',\n",
       " 'آذار',\n",
       " 'نيسان',\n",
       " 'أيار',\n",
       " 'حزيران',\n",
       " 'تموز',\n",
       " 'آب',\n",
       " 'أيلول',\n",
       " 'تشرين',\n",
       " 'دولار',\n",
       " 'دينار',\n",
       " 'ريال',\n",
       " 'درهم',\n",
       " 'ليرة',\n",
       " 'جنيه',\n",
       " 'قرش',\n",
       " 'مليم',\n",
       " 'فلس',\n",
       " 'هللة',\n",
       " 'سنتيم',\n",
       " 'يورو',\n",
       " 'ين',\n",
       " 'يوان',\n",
       " 'شيكل',\n",
       " 'واحد',\n",
       " 'اثنان',\n",
       " 'ثلاثة',\n",
       " 'أربعة',\n",
       " 'خمسة',\n",
       " 'ستة',\n",
       " 'سبعة',\n",
       " 'ثمانية',\n",
       " 'تسعة',\n",
       " 'عشرة',\n",
       " 'أحد',\n",
       " 'اثنا',\n",
       " 'اثني',\n",
       " 'إحدى',\n",
       " 'ثلاث',\n",
       " 'أربع',\n",
       " 'خمس',\n",
       " 'ست',\n",
       " 'سبع',\n",
       " 'ثماني',\n",
       " 'تسع',\n",
       " 'عشر',\n",
       " 'ثمان',\n",
       " 'سبت',\n",
       " 'أحد',\n",
       " 'اثنين',\n",
       " 'ثلاثاء',\n",
       " 'أربعاء',\n",
       " 'خميس',\n",
       " 'جمعة',\n",
       " 'أول',\n",
       " 'ثان',\n",
       " 'ثاني',\n",
       " 'ثالث',\n",
       " 'رابع',\n",
       " 'خامس',\n",
       " 'سادس',\n",
       " 'سابع',\n",
       " 'ثامن',\n",
       " 'تاسع',\n",
       " 'عاشر',\n",
       " 'حادي',\n",
       " 'أ',\n",
       " 'ب',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ك',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ي',\n",
       " 'ء',\n",
       " 'ى',\n",
       " 'آ',\n",
       " 'ؤ',\n",
       " 'ئ',\n",
       " 'أ',\n",
       " 'ة',\n",
       " 'ألف',\n",
       " 'باء',\n",
       " 'تاء',\n",
       " 'ثاء',\n",
       " 'جيم',\n",
       " 'حاء',\n",
       " 'خاء',\n",
       " 'دال',\n",
       " 'ذال',\n",
       " 'راء',\n",
       " 'زاي',\n",
       " 'سين',\n",
       " 'شين',\n",
       " 'صاد',\n",
       " 'ضاد',\n",
       " 'طاء',\n",
       " 'ظاء',\n",
       " 'عين',\n",
       " 'غين',\n",
       " 'فاء',\n",
       " 'قاف',\n",
       " 'كاف',\n",
       " 'لام',\n",
       " 'ميم',\n",
       " 'نون',\n",
       " 'هاء',\n",
       " 'واو',\n",
       " 'ياء',\n",
       " 'همزة',\n",
       " 'ي',\n",
       " 'نا',\n",
       " 'ك',\n",
       " 'كن',\n",
       " 'ه',\n",
       " 'إياه',\n",
       " 'إياها',\n",
       " 'إياهما',\n",
       " 'إياهم',\n",
       " 'إياهن',\n",
       " 'إياك',\n",
       " 'إياكما',\n",
       " 'إياكم',\n",
       " 'إياك',\n",
       " 'إياكن',\n",
       " 'إياي',\n",
       " 'إيانا',\n",
       " 'أولالك',\n",
       " 'تانِ',\n",
       " 'تانِك',\n",
       " 'تِه',\n",
       " 'تِي',\n",
       " 'تَيْنِ',\n",
       " 'ثمّ',\n",
       " 'ثمّة',\n",
       " 'ذانِ',\n",
       " 'ذِه',\n",
       " 'ذِي',\n",
       " 'ذَيْنِ',\n",
       " 'هَؤلاء',\n",
       " 'هَاتانِ',\n",
       " 'هَاتِه',\n",
       " 'هَاتِي',\n",
       " 'هَاتَيْنِ',\n",
       " 'هَذا',\n",
       " 'هَذانِ',\n",
       " 'هَذِه',\n",
       " 'هَذِي',\n",
       " 'هَذَيْنِ',\n",
       " 'الألى',\n",
       " 'الألاء',\n",
       " 'أل',\n",
       " 'أنّى',\n",
       " 'أيّ',\n",
       " 'ّأيّان',\n",
       " 'أنّى',\n",
       " 'أيّ',\n",
       " 'ّأيّان',\n",
       " 'ذيت',\n",
       " 'كأيّ',\n",
       " 'كأيّن',\n",
       " 'بضع',\n",
       " 'فلان',\n",
       " 'وا',\n",
       " 'آمينَ',\n",
       " 'آهِ',\n",
       " 'آهٍ',\n",
       " 'آهاً',\n",
       " 'أُفٍّ',\n",
       " 'أُفٍّ',\n",
       " 'أفٍّ',\n",
       " 'أمامك',\n",
       " 'أمامكَ',\n",
       " 'أوّهْ',\n",
       " 'إلَيْكَ',\n",
       " 'إلَيْكَ',\n",
       " 'إليكَ',\n",
       " 'إليكنّ',\n",
       " 'إيهٍ',\n",
       " 'بخٍ',\n",
       " 'بسّ',\n",
       " 'بَسْ',\n",
       " 'بطآن',\n",
       " 'بَلْهَ',\n",
       " 'حاي',\n",
       " 'حَذارِ',\n",
       " 'حيَّ',\n",
       " 'حيَّ',\n",
       " 'دونك',\n",
       " 'رويدك',\n",
       " 'سرعان',\n",
       " 'شتانَ',\n",
       " 'شَتَّانَ',\n",
       " 'صهْ',\n",
       " 'صهٍ',\n",
       " 'طاق',\n",
       " 'طَق',\n",
       " 'عَدَسْ',\n",
       " 'كِخ',\n",
       " 'مكانَك',\n",
       " 'مكانَك',\n",
       " 'مكانَك',\n",
       " 'مكانكم',\n",
       " 'مكانكما',\n",
       " 'مكانكنّ',\n",
       " 'نَخْ',\n",
       " 'هاكَ',\n",
       " 'هَجْ',\n",
       " 'هلم',\n",
       " 'هيّا',\n",
       " 'هَيْهات',\n",
       " 'وا',\n",
       " 'واهاً',\n",
       " 'وراءَك',\n",
       " 'وُشْكَانَ',\n",
       " 'وَيْ',\n",
       " 'يفعلان',\n",
       " 'تفعلان',\n",
       " 'يفعلون',\n",
       " 'تفعلون',\n",
       " 'تفعلين',\n",
       " 'اتخذ',\n",
       " 'ألفى',\n",
       " 'تخذ',\n",
       " 'ترك',\n",
       " 'تعلَّم',\n",
       " 'جعل',\n",
       " 'حجا',\n",
       " 'حبيب',\n",
       " 'خال',\n",
       " 'حسب',\n",
       " 'خال',\n",
       " 'درى',\n",
       " 'رأى',\n",
       " 'زعم',\n",
       " 'صبر',\n",
       " 'ظنَّ',\n",
       " 'عدَّ',\n",
       " 'علم',\n",
       " 'غادر',\n",
       " 'ذهب',\n",
       " 'وجد',\n",
       " 'ورد',\n",
       " 'وهب',\n",
       " 'أسكن',\n",
       " 'أطعم',\n",
       " 'أعطى',\n",
       " 'رزق',\n",
       " 'زود',\n",
       " 'سقى',\n",
       " 'كسا',\n",
       " 'أخبر',\n",
       " 'أرى',\n",
       " 'أعلم',\n",
       " 'أنبأ',\n",
       " 'حدَث',\n",
       " 'خبَّر',\n",
       " 'نبَّا',\n",
       " 'أفعل به',\n",
       " 'ما أفعله',\n",
       " 'بئس',\n",
       " 'ساء',\n",
       " 'طالما',\n",
       " 'قلما',\n",
       " 'لات',\n",
       " 'لكنَّ',\n",
       " 'ءَ',\n",
       " 'أجل',\n",
       " 'إذاً',\n",
       " 'أمّا',\n",
       " 'إمّا',\n",
       " 'إنَّ',\n",
       " 'أنًّ',\n",
       " 'أى',\n",
       " 'إى',\n",
       " 'أيا',\n",
       " 'ب',\n",
       " 'ثمَّ',\n",
       " 'جلل',\n",
       " 'جير',\n",
       " 'رُبَّ',\n",
       " 'س',\n",
       " 'علًّ',\n",
       " 'ف',\n",
       " 'كأنّ',\n",
       " 'كلَّا',\n",
       " 'كى',\n",
       " 'ل',\n",
       " 'لات',\n",
       " 'لعلَّ',\n",
       " 'لكنَّ',\n",
       " 'لكنَّ',\n",
       " 'م',\n",
       " 'نَّ',\n",
       " 'هلّا',\n",
       " 'وا',\n",
       " 'أل',\n",
       " 'إلّا',\n",
       " 'ت',\n",
       " 'ك',\n",
       " 'لمّا',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ا',\n",
       " 'ي',\n",
       " 'تجاه',\n",
       " 'تلقاء',\n",
       " 'جميع',\n",
       " 'حسب',\n",
       " 'سبحان',\n",
       " 'شبه',\n",
       " 'لعمر',\n",
       " 'مثل',\n",
       " 'معاذ',\n",
       " 'أبو',\n",
       " 'أخو',\n",
       " 'حمو',\n",
       " 'فو',\n",
       " 'مئة',\n",
       " 'مئتان',\n",
       " 'ثلاثمئة',\n",
       " 'أربعمئة',\n",
       " 'خمسمئة',\n",
       " 'ستمئة',\n",
       " 'سبعمئة',\n",
       " 'ثمنمئة',\n",
       " 'تسعمئة',\n",
       " 'مائة',\n",
       " 'ثلاثمائة',\n",
       " 'أربعمائة',\n",
       " 'خمسمائة',\n",
       " 'ستمائة',\n",
       " 'سبعمائة',\n",
       " 'ثمانمئة',\n",
       " 'تسعمائة',\n",
       " 'عشرون',\n",
       " 'ثلاثون',\n",
       " 'اربعون',\n",
       " 'خمسون',\n",
       " 'ستون',\n",
       " 'سبعون',\n",
       " 'ثمانون',\n",
       " 'تسعون',\n",
       " 'عشرين',\n",
       " 'ثلاثين',\n",
       " 'اربعين',\n",
       " 'خمسين',\n",
       " 'ستين',\n",
       " 'سبعين',\n",
       " 'ثمانين',\n",
       " 'تسعين',\n",
       " 'بضع',\n",
       " 'نيف',\n",
       " 'أجمع',\n",
       " 'جميع',\n",
       " 'عامة',\n",
       " 'عين',\n",
       " 'نفس',\n",
       " 'لا سيما',\n",
       " 'أصلا',\n",
       " 'أهلا',\n",
       " 'أيضا',\n",
       " 'بؤسا',\n",
       " 'بعدا',\n",
       " 'بغتة',\n",
       " 'تعسا',\n",
       " 'حقا',\n",
       " 'حمدا',\n",
       " 'خلافا',\n",
       " 'خاصة',\n",
       " 'دواليك',\n",
       " 'سحقا',\n",
       " 'سرا',\n",
       " 'سمعا',\n",
       " 'صبرا',\n",
       " 'صدقا',\n",
       " 'صراحة',\n",
       " 'طرا',\n",
       " 'عجبا',\n",
       " 'عيانا',\n",
       " 'غالبا',\n",
       " 'فرادى',\n",
       " 'فضلا',\n",
       " 'قاطبة',\n",
       " 'كثيرا',\n",
       " 'لبيك',\n",
       " 'معاذ',\n",
       " 'أبدا',\n",
       " 'إزاء',\n",
       " 'أصلا',\n",
       " 'الآن',\n",
       " 'أمد',\n",
       " 'أمس',\n",
       " 'آنفا',\n",
       " 'آناء',\n",
       " 'أنّى',\n",
       " 'أول',\n",
       " 'أيّان',\n",
       " 'تارة',\n",
       " 'ثمّ',\n",
       " 'ثمّة',\n",
       " 'حقا',\n",
       " 'صباح',\n",
       " 'مساء',\n",
       " 'ضحوة',\n",
       " 'عوض',\n",
       " 'غدا',\n",
       " 'غداة',\n",
       " 'قطّ',\n",
       " 'كلّما',\n",
       " 'لدن',\n",
       " 'لمّا',\n",
       " 'مرّة',\n",
       " 'قبل',\n",
       " 'خلف',\n",
       " 'أمام',\n",
       " 'فوق',\n",
       " 'تحت',\n",
       " 'يمين',\n",
       " 'شمال',\n",
       " 'ارتدّ',\n",
       " 'استحال',\n",
       " 'أصبح',\n",
       " 'أضحى',\n",
       " 'آض',\n",
       " 'أمسى',\n",
       " 'انقلب',\n",
       " 'بات',\n",
       " 'تبدّل',\n",
       " 'تحوّل',\n",
       " 'حار',\n",
       " 'رجع',\n",
       " 'راح',\n",
       " 'صار',\n",
       " 'ظلّ',\n",
       " 'عاد',\n",
       " 'غدا',\n",
       " 'كان',\n",
       " 'ما انفك',\n",
       " 'ما برح',\n",
       " 'مادام',\n",
       " 'مازال',\n",
       " 'مافتئ',\n",
       " 'ابتدأ',\n",
       " 'أخذ',\n",
       " 'اخلولق',\n",
       " 'أقبل',\n",
       " 'انبرى',\n",
       " 'أنشأ',\n",
       " 'أوشك',\n",
       " 'جعل',\n",
       " 'حرى',\n",
       " 'شرع',\n",
       " 'طفق',\n",
       " 'علق',\n",
       " 'قام',\n",
       " 'كرب',\n",
       " 'كاد',\n",
       " 'هبّa',\n",
       " 'ad',\n",
       " 'altı',\n",
       " 'altmış',\n",
       " 'amma',\n",
       " 'arasında',\n",
       " 'artıq',\n",
       " 'ay',\n",
       " 'az',\n",
       " 'bax',\n",
       " 'belə',\n",
       " 'bəli',\n",
       " 'bəlkə',\n",
       " 'beş',\n",
       " 'bəy',\n",
       " 'bəzən',\n",
       " 'bəzi',\n",
       " 'bilər',\n",
       " 'bir',\n",
       " 'biraz',\n",
       " 'biri',\n",
       " 'birşey',\n",
       " 'biz',\n",
       " 'bizim',\n",
       " 'bizlər',\n",
       " 'bu',\n",
       " 'buna',\n",
       " 'bundan',\n",
       " 'bunların',\n",
       " 'bunu',\n",
       " 'bunun',\n",
       " 'buradan',\n",
       " 'bütün',\n",
       " 'ci',\n",
       " 'cı',\n",
       " 'çox',\n",
       " 'cu',\n",
       " 'cü',\n",
       " 'çünki',\n",
       " 'da',\n",
       " 'daha',\n",
       " 'də',\n",
       " 'dedi',\n",
       " 'dək',\n",
       " 'dən',\n",
       " 'dəqiqə',\n",
       " 'deyil',\n",
       " 'dir',\n",
       " 'doqquz',\n",
       " 'doqsan',\n",
       " 'dörd',\n",
       " 'düz',\n",
       " 'ə',\n",
       " 'edən',\n",
       " 'edir',\n",
       " 'əgər',\n",
       " 'əlbəttə',\n",
       " 'elə',\n",
       " 'əlli',\n",
       " 'ən',\n",
       " 'əslində',\n",
       " 'et',\n",
       " 'etdi',\n",
       " 'etmə',\n",
       " 'etmək',\n",
       " 'faiz',\n",
       " 'gilə',\n",
       " 'görə',\n",
       " 'ha',\n",
       " 'haqqında',\n",
       " 'harada',\n",
       " 'hə',\n",
       " 'heç',\n",
       " 'həm',\n",
       " 'həmin',\n",
       " 'həmişə',\n",
       " 'hər',\n",
       " 'ı',\n",
       " 'idi',\n",
       " 'iki',\n",
       " 'il',\n",
       " 'ildə',\n",
       " 'ilə',\n",
       " 'ilk',\n",
       " 'in',\n",
       " 'indi',\n",
       " 'isə',\n",
       " 'istifadə',\n",
       " 'iyirmi',\n",
       " 'ki',\n",
       " 'kim',\n",
       " 'kimə',\n",
       " 'kimi',\n",
       " 'lakin',\n",
       " 'lap',\n",
       " 'məhz',\n",
       " 'mən',\n",
       " 'mənə',\n",
       " 'mirşey',\n",
       " 'nə',\n",
       " 'nəhayət',\n",
       " 'niyə',\n",
       " 'o',\n",
       " 'obirisi',\n",
       " 'of',\n",
       " 'olan',\n",
       " 'olar',\n",
       " 'olaraq',\n",
       " 'oldu',\n",
       " 'olduğu',\n",
       " 'olmadı',\n",
       " 'olmaz',\n",
       " 'olmuşdur',\n",
       " 'olsun',\n",
       " 'olur',\n",
       " 'on',\n",
       " 'ona',\n",
       " 'ondan',\n",
       " 'onlar',\n",
       " 'onlardan',\n",
       " 'onların ',\n",
       " 'onsuzda',\n",
       " 'onu',\n",
       " 'onun',\n",
       " 'oradan',\n",
       " 'otuz',\n",
       " 'öz',\n",
       " 'özü',\n",
       " 'qarşı',\n",
       " 'qədər',\n",
       " 'qırx',\n",
       " 'saat',\n",
       " 'sadəcə',\n",
       " 'saniyə',\n",
       " 'səhv',\n",
       " 'səkkiz',\n",
       " 'səksən',\n",
       " 'sən',\n",
       " 'sənə',\n",
       " 'sənin',\n",
       " 'siz',\n",
       " 'sizin',\n",
       " 'sizlər',\n",
       " 'sonra',\n",
       " 'təəssüf',\n",
       " 'ü',\n",
       " 'üç',\n",
       " 'üçün',\n",
       " 'var',\n",
       " 'və',\n",
       " 'xan',\n",
       " 'xanım',\n",
       " 'xeyr',\n",
       " 'ya',\n",
       " 'yalnız',\n",
       " 'yaxşı',\n",
       " 'yeddi',\n",
       " 'yenə',\n",
       " 'yəni',\n",
       " 'yetmiş',\n",
       " 'yox',\n",
       " 'yoxdur',\n",
       " 'yoxsa',\n",
       " 'yüz',\n",
       " 'zamanahala',\n",
       " 'aitzitik',\n",
       " 'al',\n",
       " 'ala ',\n",
       " 'alabadere',\n",
       " 'alabaina',\n",
       " 'alabaina',\n",
       " 'aldiz ',\n",
       " 'alta',\n",
       " 'amaitu',\n",
       " 'amaitzeko',\n",
       " 'anitz',\n",
       " 'antzina',\n",
       " 'arabera',\n",
       " 'arabera',\n",
       " 'arabera',\n",
       " 'argi',\n",
       " 'arratsaldero',\n",
       " 'arte',\n",
       " 'artean',\n",
       " 'asko',\n",
       " 'aspaldiko',\n",
       " 'aurrera',\n",
       " 'aurrera',\n",
       " 'azkenez',\n",
       " 'azkenik',\n",
       " 'azkenik',\n",
       " 'ba',\n",
       " 'bada',\n",
       " 'bada ',\n",
       " 'bada ',\n",
       " 'bada ',\n",
       " 'badarik',\n",
       " 'badarik',\n",
       " 'badarik ',\n",
       " 'badere',\n",
       " 'bai',\n",
       " 'baina',\n",
       " 'baina',\n",
       " 'baina ',\n",
       " 'baino',\n",
       " 'baino',\n",
       " 'baino',\n",
       " 'baino',\n",
       " 'baita',\n",
       " 'baizik ',\n",
       " 'baldin',\n",
       " 'baldin',\n",
       " 'barren',\n",
       " 'bat',\n",
       " 'batean',\n",
       " 'batean',\n",
       " 'batean',\n",
       " 'batean',\n",
       " 'batek',\n",
       " 'baten',\n",
       " 'batera',\n",
       " 'batez',\n",
       " 'bati',\n",
       " 'batzuei',\n",
       " 'batzuek',\n",
       " 'batzuetan',\n",
       " 'batzuk',\n",
       " 'bazen',\n",
       " 'bederen',\n",
       " 'bederik',\n",
       " 'beharrez',\n",
       " 'behiala',\n",
       " 'behin',\n",
       " 'behin',\n",
       " 'behin',\n",
       " 'behin',\n",
       " 'behinik',\n",
       " 'behinola',\n",
       " 'behintzat',\n",
       " 'bera',\n",
       " 'beraiek',\n",
       " 'beranduago',\n",
       " 'berau',\n",
       " 'berauek',\n",
       " 'beraz',\n",
       " 'beraz ',\n",
       " 'bere',\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will give everything\n",
    "stopwords.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac826fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will give English\n",
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b51315f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4dc4dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "81cd6dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a3b5892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Lionel',\n",
       " 'Messi',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'of',\n",
       " 'all',\n",
       " 'time',\n",
       " '.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91ec80ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c431756",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a72f95d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'name', 'Lionel', 'Messi', ',', 'I', 'greatest', 'time', '.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77b0044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to write in list comprehensions\n",
    "filtered_sentence = [w for w in words if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00f8da60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'name', 'Lionel', 'Messi', ',', 'I', 'greatest', 'time', '.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d1bfd",
   "metadata": {},
   "source": [
    "# Better Stemming\n",
    "You have a couple of options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae65ba7c",
   "metadata": {},
   "source": [
    "### Porter Stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f55e0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "749fb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "plurals = ['caresses', 'flies', 'dies', 'mules', 'denied','died', \n",
    "           'agreed', 'owned', 'humbled', 'sized','meeting', 'stating', \n",
    "           'siezing', 'itemization','sensational', 'traditional', \n",
    "           'reference', 'colonizer','plotted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83906877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caresses >>> caress\n",
      "flies >>> fli\n",
      "dies >>> die\n",
      "mules >>> mule\n",
      "denied >>> deni\n",
      "died >>> die\n",
      "agreed >>> agre\n",
      "owned >>> own\n",
      "humbled >>> humbl\n",
      "sized >>> size\n",
      "meeting >>> meet\n",
      "stating >>> state\n",
      "siezing >>> siez\n",
      "itemization >>> item\n",
      "sensational >>> sensat\n",
      "traditional >>> tradit\n",
      "reference >>> refer\n",
      "colonizer >>> colon\n",
      "plotted >>> plot\n"
     ]
    }
   ],
   "source": [
    "for word in plurals:\n",
    "    print(f\"{word} >>> {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc6153",
   "metadata": {},
   "source": [
    "### Snowball stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e851e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0927b2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6be4070",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2fba7255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generous'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_stemmer.stem(\"generously\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6fce1e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gener'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"generously\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41e24c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caresses >>> caress\n",
      "flies >>> fli\n",
      "dies >>> die\n",
      "mules >>> mule\n",
      "denied >>> deni\n",
      "died >>> die\n",
      "agreed >>> agre\n",
      "owned >>> own\n",
      "humbled >>> humbl\n",
      "sized >>> size\n",
      "meeting >>> meet\n",
      "stating >>> state\n",
      "siezing >>> siez\n",
      "itemization >>> item\n",
      "sensational >>> sensat\n",
      "traditional >>> tradit\n",
      "reference >>> refer\n",
      "colonizer >>> colon\n",
      "plotted >>> plot\n"
     ]
    }
   ],
   "source": [
    "for word in plurals:\n",
    "    print(f\"{word} >>> {sn_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b86f6c",
   "metadata": {},
   "source": [
    "# Lemmeization\n",
    "Retrieving the source of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "465faf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ff94755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caresses >>> caress\n",
      "flies >>> fly\n",
      "dies >>> dy\n",
      "mules >>> mule\n",
      "denied >>> denied\n",
      "died >>> died\n",
      "agreed >>> agreed\n",
      "owned >>> owned\n",
      "humbled >>> humbled\n",
      "sized >>> sized\n",
      "meeting >>> meeting\n",
      "stating >>> stating\n",
      "siezing >>> siezing\n",
      "itemization >>> itemization\n",
      "sensational >>> sensational\n",
      "traditional >>> traditional\n",
      "reference >>> reference\n",
      "colonizer >>> colonizer\n",
      "plotted >>> plotted\n"
     ]
    }
   ],
   "source": [
    "for word in plurals:\n",
    "    print(f\"{word} >>> {lemmatizer.lemmatize(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a6a62",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- How to install NLTK and it's data\n",
    "- How to use nltk tokenizers\n",
    "- NLTK Stemmers\n",
    "- NLTK Lemmatizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcfd492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
